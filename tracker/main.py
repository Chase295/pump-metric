import asyncio
import websockets
import json
import time
import asyncpg
import os
from datetime import datetime, timezone
from dateutil import parser
from zoneinfo import ZoneInfo
from collections import Counter
from aiohttp import web
from prometheus_client import Counter as PromCounter, Gauge, Histogram, generate_latest, CONTENT_TYPE_LATEST
from db_migration import check_and_create_schema

# --- KONFIGURATION ---
DB_DSN = os.getenv("DB_DSN", "postgresql://postgres:9HVxi6hN6j7xpmqUx84o@100.118.155.75:5432/crypto")
WS_URI = os.getenv("WS_URI", "wss://pumpportal.fun/api/data")
DB_REFRESH_INTERVAL = int(os.getenv("DB_REFRESH_INTERVAL", "10"))
SOL_RESERVES_FULL = float(os.getenv("SOL_RESERVES_FULL", "85.0"))
AGE_CALCULATION_OFFSET_MIN = int(os.getenv("AGE_CALCULATION_OFFSET_MIN", "60"))
DB_RETRY_DELAY = int(os.getenv("DB_RETRY_DELAY", "5"))
WS_RETRY_DELAY = int(os.getenv("WS_RETRY_DELAY", "3"))
WS_MAX_RETRY_DELAY = int(os.getenv("WS_MAX_RETRY_DELAY", "60"))
WS_PING_INTERVAL = int(os.getenv("WS_PING_INTERVAL", "20"))
WS_PING_TIMEOUT = int(os.getenv("WS_PING_TIMEOUT", "10"))
WS_CONNECTION_TIMEOUT = int(os.getenv("WS_CONNECTION_TIMEOUT", "30"))
HEALTH_PORT = int(os.getenv("HEALTH_PORT", "8000"))
TRADE_BUFFER_SECONDS = int(os.getenv("TRADE_BUFFER_SECONDS", "180"))  # 180 Sekunden (3 Minuten) Buffer f√ºr verpasste Trades

# ZEITZONEN
GERMAN_TZ = ZoneInfo("Europe/Berlin")

# --- PROMETHEUS METRICS ---
trades_received = PromCounter("tracker_trades_received_total", "Anzahl empfangener Trades")
trades_processed = PromCounter("tracker_trades_processed_total", "Anzahl verarbeiteter Trades")
trades_from_buffer = PromCounter("tracker_trades_from_buffer_total", "Anzahl Trades aus Buffer verarbeitet")
metrics_saved = PromCounter("tracker_metrics_saved_total", "Anzahl gespeicherter Metriken")
coins_tracked = Gauge("tracker_coins_tracked", "Anzahl aktuell getrackter Coins")
coins_graduated = PromCounter("tracker_coins_graduated_total", "Anzahl graduierter Coins")
coins_finished = PromCounter("tracker_coins_finished_total", "Anzahl beendeter Coins")
phase_switches = PromCounter("tracker_phase_switches_total", "Anzahl Phasen-Wechsel")
db_errors = PromCounter("tracker_db_errors_total", "DB Fehler", ["type"])
ws_reconnects = PromCounter("tracker_ws_reconnects_total", "WebSocket Reconnects")
ws_connected = Gauge("tracker_ws_connected", "WebSocket Status (1=connected)")
db_connected = Gauge("tracker_db_connected", "DB Status (1=connected)")
uptime_seconds = Gauge("tracker_uptime_seconds", "Uptime in Sekunden")
last_trade_timestamp = Gauge("tracker_last_trade_timestamp", "Timestamp des letzten Trades")
connection_duration = Gauge("tracker_connection_duration_seconds", "Dauer der aktuellen Verbindung")
db_query_duration = Histogram("tracker_db_query_duration_seconds", "Dauer von DB-Queries")
flush_duration = Histogram("tracker_flush_duration_seconds", "Dauer von Metric-Flushes")
buffer_size = Gauge("tracker_trade_buffer_size", "Anzahl Trades im Buffer")
buffer_trades_total = PromCounter("tracker_buffer_trades_total", "Gesamt Trades im Buffer gespeichert")

# --- STATUS TRACKING ---
tracker_status = {
    "db_connected": False,
    "ws_connected": False,
    "last_error": None,
    "start_time": time.time(),
    "connection_start": None,
    "last_message_time": None,
    "reconnect_count": 0,
    "total_trades": 0,
    "total_metrics_saved": 0
}

# Globale Tracker-Instanz f√ºr Health-Check
_tracker_instance = None

async def metrics_handler(request):
    """Prometheus Metrics Endpoint"""
    uptime_seconds.set(time.time() - tracker_status["start_time"])
    if tracker_status["connection_start"]:
        connection_duration.set(time.time() - tracker_status["connection_start"])
    return web.Response(body=generate_latest(), content_type="text/plain; version=0.0.4", charset="utf-8")

async def health_check(request):
    global _tracker_instance
    db_status = tracker_status.get("db_connected", False)
    ws_status = tracker_status.get("ws_connected", False)
    uptime = time.time() - tracker_status["start_time"]
    last_msg = tracker_status.get("last_message_time")
    
    # Buffer-Statistiken berechnen
    buffer_stats = {
        "total_trades_in_buffer": 0,
        "coins_with_buffer": 0,
        "buffer_details": {}
    }
    
    # Hole Tracker-Instanz (wenn verf√ºgbar)
    if _tracker_instance and hasattr(_tracker_instance, 'trade_buffer'):
        buffer_stats["total_trades_in_buffer"] = sum(len(trades) for trades in _tracker_instance.trade_buffer.values())
        buffer_stats["coins_with_buffer"] = len(_tracker_instance.trade_buffer)
        
        # Top 10 Coins mit meisten Trades im Buffer
        coin_buffer_counts = [(mint, len(trades)) for mint, trades in _tracker_instance.trade_buffer.items()]
        coin_buffer_counts.sort(key=lambda x: x[1], reverse=True)
        
        buffer_stats["buffer_details"] = {
            coin[:12] + "..." if len(coin) > 12 else coin: count 
            for coin, count in coin_buffer_counts[:10]
        }
    
    health_data = {
        "status": "healthy" if (db_status and ws_status) else "degraded",
        "db_connected": db_status,
        "ws_connected": ws_status,
        "uptime_seconds": int(uptime),
        "total_trades": tracker_status["total_trades"],
        "total_metrics_saved": tracker_status["total_metrics_saved"],
        "last_message_ago": int(time.time() - last_msg) if last_msg else None,
        "reconnect_count": tracker_status["reconnect_count"],
        "last_error": tracker_status.get("last_error"),
        "buffer_stats": buffer_stats
    }
    
    status_code = 200 if (db_status and ws_status) else 503
    return web.json_response(health_data, status=status_code)

async def start_health_server():
    """Startet den Health-Check Server - muss sofort verf√ºgbar sein"""
    app = web.Application()
    app.add_routes([
        web.get("/health", health_check),
        web.get("/metrics", metrics_handler)
    ])
    runner = web.AppRunner(app)
    await runner.setup()
    site = web.TCPSite(runner, "0.0.0.0", HEALTH_PORT)
    await site.start()
    print(f"üè• Health-Check Server l√§uft auf Port {HEALTH_PORT}", flush=True)
    print(f"üìä Prometheus Metrics auf http://localhost:{HEALTH_PORT}/metrics", flush=True)
    print(f"‚úÖ Health-Endpoint verf√ºgbar: http://0.0.0.0:{HEALTH_PORT}/health", flush=True)

class Tracker:
    def __init__(self):
        self.pool = None
        self.phases_config = {}
        self.watchlist = {}
        self.subscribed_mints = set()
        self.sorted_phase_ids = []
        # {TRADE_BUFFER_SECONDS}-Sekunden-Buffer f√ºr alle empfangenen Trades (Standard: 180s = 3 Minuten)
        # Struktur: {mint: [(timestamp, trade_data), ...]}
        self.trade_buffer = {}
        self.last_buffer_cleanup = time.time()
        # Track welche Coins bereits √ºber subscribeNewToken abonniert wurden
        self.early_subscribed_mints = set()

    async def init_db_connection(self):
        while True:
            try:
                if self.pool:
                    await self.pool.close()
                self.pool = await asyncpg.create_pool(DB_DSN, min_size=1, max_size=10)
                
                # Automatische Schema-Migration beim Start
                print("üîç Pr√ºfe und aktualisiere Datenbank-Schema...", flush=True)
                schema_ok = await check_and_create_schema(self.pool)
                if not schema_ok:
                    print("‚ö†Ô∏è  Schema-Check fehlgeschlagen, aber Verbindung funktioniert", flush=True)
                
                rows = await self.pool.fetch("SELECT * FROM ref_coin_phases ORDER BY id ASC")
                self.phases_config = {}
                for row in rows:
                    self.phases_config[row["id"]] = {
                        "interval": row["interval_seconds"],
                        "max_age": row["max_age_minutes"],
                        "name": row["name"]
                    }
                self.sorted_phase_ids = sorted(self.phases_config.keys())
                print(f"‚úÖ DB verbunden. Geladene Phasen: {self.sorted_phase_ids}", flush=True)
                tracker_status["db_connected"] = True
                tracker_status["last_error"] = None
                db_connected.set(1)
                return
            except Exception as e:
                tracker_status["db_connected"] = False
                tracker_status["last_error"] = f"db_error: {str(e)[:100]}"
                db_connected.set(0)
                db_errors.labels(type="connection").inc()
                print(f"‚ùå DB Verbindungsfehler: {e}", flush=True)
                print(f"‚è≥ Retry in {DB_RETRY_DELAY}s...", flush=True)
                await asyncio.sleep(DB_RETRY_DELAY)

    async def get_active_streams(self):
        try:
            with db_query_duration.time():
                # Zuerst: Repariere fehlende Streams (sicherheitshalber)
                try:
                    await self.pool.execute("SELECT repair_missing_streams()")
                except Exception as e:
                    # Funktion existiert m√∂glicherweise noch nicht - ignorieren
                    pass
                
                # Dann: Hole aktive Streams
                sql = """
                    SELECT cs.token_address, cs.current_phase_id, dc.token_created_at, cs.started_at
                    FROM coin_streams cs
                    JOIN discovered_coins dc ON cs.token_address = dc.token_address
                    WHERE cs.is_active = TRUE
                """
                rows = await self.pool.fetch(sql)
                results = {}
                for row in rows:
                    mint = row["token_address"]
                    created_at = row["token_created_at"]
                    started_at = row["started_at"]
                    if not created_at: created_at = datetime.now(timezone.utc)
                    if created_at.tzinfo is None: created_at = created_at.replace(tzinfo=timezone.utc)
                    if started_at and started_at.tzinfo is None: started_at = started_at.replace(tzinfo=timezone.utc)
                    results[mint] = {
                        "phase_id": row["current_phase_id"],
                        "created_at": created_at,
                        "started_at": started_at or created_at
                    }
                
                # Pr√ºfe auf L√ºcken (nur alle 60 Sekunden, um Performance zu schonen)
                if not hasattr(self, '_last_gap_check') or (time.time() - self._last_gap_check) > 60:
                    try:
                        gap_result = await self.pool.fetchrow("SELECT * FROM check_stream_gaps()")
                        if gap_result and gap_result["missing_streams_count"] > 0:
                            print(f"‚ö†Ô∏è WARNUNG: {gap_result['missing_streams_count']} Coins ohne Stream gefunden!", flush=True)
                            if gap_result["coins_without_streams"]:
                                print(f"   Betroffene Coins: {', '.join(gap_result['coins_without_streams'][:5])}...", flush=True)
                    except Exception as e:
                        # Funktion existiert m√∂glicherweise noch nicht - ignorieren
                        pass
                    self._last_gap_check = time.time()
                
                return results
        except Exception as e:
            print(f"‚ö†Ô∏è DB Query Error: {e}", flush=True)
            tracker_status["db_connected"] = False
            db_connected.set(0)
            db_errors.labels(type="query").inc()
            raise

    async def switch_phase(self, mint, old_phase, new_phase):
        try:
            print(f"üÜô UPGRADE: {mint} Phase {old_phase} -> {new_phase}", flush=True)
            async with self.pool.acquire() as conn:
                await conn.execute("UPDATE coin_streams SET current_phase_id = $1 WHERE token_address = $2", new_phase, mint)
            phase_switches.inc()
        except Exception as e:
            print(f"‚ö†Ô∏è Phase Switch Error: {e}", flush=True)
            tracker_status["db_connected"] = False
            db_connected.set(0)
            db_errors.labels(type="update").inc()

    async def stop_tracking(self, mint, is_graduation=False):
        try:
            if is_graduation:
                print(f"üéâ GRADUATION: {mint} geht zu Raydium! Tracking beendet.", flush=True)
                final_phase = 100
                graduated_flag = True
                coins_graduated.inc()
            else:
                print(f"üèÅ FINISHED: {mint} Lifecycle beendet.", flush=True)
                final_phase = 99
                graduated_flag = False
                coins_finished.inc()
            async with self.pool.acquire() as conn:
                await conn.execute("""
                    UPDATE coin_streams
                    SET is_active = FALSE,
                        current_phase_id = $2,
                        is_graduated = $3
                    WHERE token_address = $1
                """, mint, final_phase, graduated_flag)
        except Exception as e:
            print(f"‚ö†Ô∏è Stop Tracking Error: {e}", flush=True)
            tracker_status["db_connected"] = False
            db_connected.set(0)
            db_errors.labels(type="update").inc()
        finally:
            if mint in self.watchlist: del self.watchlist[mint]
            if mint in self.subscribed_mints: self.subscribed_mints.remove(mint)
            coins_tracked.set(len(self.watchlist))

    def get_empty_buffer(self):
        return {
            "open": None, "high": -1, "low": float("inf"), "close": 0,
            "vol": 0, "vol_buy": 0, "vol_sell": 0, "buys": 0, "sells": 0,
            "micro_trades": 0, "max_buy": 0, "max_sell": 0,
            "wallets": set(), "v_sol": 0, "mcap": 0
        }

    async def run_new_token_listener(self, subscribe_queue):
        """Zweiter WebSocket-Stream: H√∂rt auf subscribeNewToken und abonniert neue Coins sofort"""
        reconnect_count = 0
        
        while True:
            try:
                print(f"üîå Verbinde NewToken-Listener... (Versuch #{reconnect_count + 1})", flush=True)
                
                async with websockets.connect(
                    WS_URI,
                    ping_interval=WS_PING_INTERVAL,
                    ping_timeout=WS_PING_TIMEOUT,
                    close_timeout=10,
                    max_size=2**23,
                    compression=None
                ) as ws_new_token:
                    print("‚úÖ NewToken-Listener verbunden! Abonniere subscribeNewToken...", flush=True)
                    
                    # Abonniere neue Coins
                    await ws_new_token.send(json.dumps({"method": "subscribeNewToken"}))
                    print("üì° subscribeNewToken aktiv - warte auf neue Coins...", flush=True)
                    
                    reconnect_count = 0
                    
                    while True:
                        try:
                            msg = await asyncio.wait_for(ws_new_token.recv(), timeout=1.0)
                            data = json.loads(msg)
                            
                            # Pr√ºfe ob es ein neuer Coin ist (create Event)
                            if data.get("txType") == "create" and "mint" in data:
                                mint = data["mint"]
                                
                                # Pr√ºfe ob Coin bereits abonniert wurde
                                if mint not in self.early_subscribed_mints:
                                    print(f"üÜï Neuer Coin erkannt: {mint[:8]}... - abonniere SOFORT f√ºr {TRADE_BUFFER_SECONDS}s Buffer!", flush=True)
                                    
                                    # Sende Abonnement-Anfrage √ºber Queue an Trade-WebSocket
                                    await subscribe_queue.put(mint)
                                    self.early_subscribed_mints.add(mint)
                                    print(f"‚úÖ {mint[:8]}... sofort abonniert - Trades werden {TRADE_BUFFER_SECONDS}s ({TRADE_BUFFER_SECONDS//60} Minuten) im Buffer gespeichert", flush=True)
                            
                        except asyncio.TimeoutError:
                            # Timeout ist okay, wir warten weiter
                            continue
                        
                        except websockets.exceptions.ConnectionClosed as e:
                            print(f"üîå NewToken-Listener Verbindung geschlossen: {e}", flush=True)
                            break
                        
                        except json.JSONDecodeError as e:
                            print(f"‚ö†Ô∏è JSON Fehler (NewToken): {e}", flush=True)
                            continue
                        
                        except Exception as e:
                            print(f"‚ö†Ô∏è NewToken-Listener Error: {e}", flush=True)
                            break
            
            except websockets.exceptions.WebSocketException as e:
                print(f"‚ùå NewToken-Listener WebSocket Exception: {e}", flush=True)
                reconnect_count += 1
            
            except Exception as e:
                print(f"‚ùå NewToken-Listener unerwarteter Fehler: {e}", flush=True)
                reconnect_count += 1
            
            delay = min(WS_RETRY_DELAY * (1 + reconnect_count * 0.5), WS_MAX_RETRY_DELAY)
            print(f"‚è≥ NewToken-Listener Reconnect in {delay:.1f}s...", flush=True)
            await asyncio.sleep(delay)

    async def run(self):
        await self.init_db_connection()
        reconnect_count = 0
        
        while True:
            try:
                print(f"üîå Verbinde zu WebSocket (Trade-Stream)... (Versuch #{reconnect_count + 1})", flush=True)
                
                async with websockets.connect(
                    WS_URI,
                    ping_interval=WS_PING_INTERVAL,
                    ping_timeout=WS_PING_TIMEOUT,
                    close_timeout=10,
                    max_size=2**23,
                    compression=None
                ) as ws:
                    tracker_status["ws_connected"] = True
                    tracker_status["connection_start"] = time.time()
                    tracker_status["last_error"] = None
                    ws_connected.set(1)
                    reconnect_count = 0
                    tracker_status["reconnect_count"] = 0
                    
                    print("‚úÖ Trade-WebSocket verbunden! Tracker l√§uft...", flush=True)
                    
                    # PRE-SUBSCRIPTION: Alle aktiven Coins beim Start abonnieren
                    print("üì° Pre-Subscription: Lade alle aktiven Coins...", flush=True)
                    try:
                        initial_streams = await self.get_active_streams()
                        if initial_streams:
                            initial_mints = list(initial_streams.keys())
                            print(f"üì° Abonniere {len(initial_mints)} aktive Coins beim Start...", flush=True)
                            await ws.send(json.dumps({"method": "subscribeTokenTrade", "keys": initial_mints}))
                            
                            # Initialisiere Watchlist f√ºr alle Coins
                            now_ts = time.time()
                            for mint in initial_mints:
                                p_id = initial_streams[mint]["phase_id"]
                                if p_id not in self.phases_config:
                                    p_id = self.sorted_phase_ids[0] if self.sorted_phase_ids else 1
                                interval = self.phases_config[p_id]["interval"]
                                self.watchlist[mint] = {
                                    "meta": initial_streams[mint],
                                    "buffer": self.get_empty_buffer(),
                                    "next_flush": now_ts + interval,
                                    "interval": interval
                                }
                                self.subscribed_mints.add(mint)
                                self.early_subscribed_mints.add(mint)  # Bereits abonniert (f√ºr Buffer-Verarbeitung wichtig)
                            
                            print(f"‚úÖ {len(initial_mints)} Coins vorab abonniert und zur Watchlist hinzugef√ºgt", flush=True)
                            coins_tracked.set(len(self.watchlist))
                        else:
                            print("‚ÑπÔ∏è  Keine aktiven Coins beim Start gefunden", flush=True)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Pre-Subscription Fehler: {e}. Weiter ohne Pre-Subscription...", flush=True)
                    
                    # STARTE ZWEITEN STREAM: NewToken-Listener im Hintergrund
                    print("üöÄ Starte NewToken-Listener (zweiter Stream f√ºr subscribeNewToken)...", flush=True)
                    subscribe_queue = asyncio.Queue()
                    new_token_task = asyncio.create_task(self.run_new_token_listener(subscribe_queue))
                    
                    last_refresh = 0
                    last_message_time = time.time()
                    
                    while True:
                        now_ts = time.time()
                        
                        # Pr√ºfe Queue f√ºr neue Abonnements vom NewToken-Listener
                        try:
                            while not subscribe_queue.empty():
                                mint = await asyncio.wait_for(subscribe_queue.get(), timeout=0.1)
                                # Abonniere Coin sofort im Trade-WebSocket
                                await ws.send(json.dumps({"method": "subscribeTokenTrade", "keys": [mint]}))
                                print(f"üì° {mint[:8]}... √ºber NewToken-Listener abonniert", flush=True)
                        except asyncio.TimeoutError:
                            pass
                        except Exception as e:
                            print(f"‚ö†Ô∏è Queue-Verarbeitung Fehler: {e}", flush=True)
                        
                        if now_ts - last_refresh > DB_REFRESH_INTERVAL:
                            try:
                                db_streams = await self.get_active_streams()
                                current_set = set(db_streams.keys())
                                to_remove = self.subscribed_mints - current_set
                                
                                if to_remove:
                                    for mint in to_remove:
                                        if mint in self.watchlist: del self.watchlist[mint]
                                        self.subscribed_mints.remove(mint)
                                
                                to_add = current_set - self.subscribed_mints
                                if to_add:
                                    print(f"üì° {len(to_add)} Coins in coin_streams aktiviert - starte Tracking...", flush=True)
                                    print(f"üîç DEBUG: to_add Coins: {[m[:8] + '...' for m in list(to_add)[:5]]}", flush=True)
                                    print(f"üîç DEBUG: early_subscribed_mints count: {len(self.early_subscribed_mints)}", flush=True)
                                    print(f"üîç DEBUG: trade_buffer count: {len(self.trade_buffer)}", flush=True)
                                    print(f"üîç DEBUG: trade_buffer keys (first 5): {[k[:8] + '...' for k in list(self.trade_buffer.keys())[:5]]}", flush=True)
                                    
                                    # Pr√ºfe ob Coins bereits √ºber NewToken-Listener abonniert wurden
                                    to_subscribe_now = []
                                    for mint in to_add:
                                        if mint not in self.early_subscribed_mints:
                                            # Coin wurde noch nicht abonniert - abonniere jetzt
                                            to_subscribe_now.append(mint)
                                            self.early_subscribed_mints.add(mint)
                                    
                                    if to_subscribe_now:
                                        print(f"üì° {len(to_subscribe_now)} Coins wurden noch nicht abonniert - abonniere jetzt...", flush=True)
                                        await ws.send(json.dumps({"method": "subscribeTokenTrade", "keys": to_subscribe_now}))
                                    
                                    # Verarbeite verpasste Trades aus dem Buffer f√ºr jeden neuen Coin
                                    total_buffer_trades = 0
                                    for mint in to_add:
                                        p_id = db_streams[mint]["phase_id"]
                                        if p_id not in self.phases_config:
                                            p_id = self.sorted_phase_ids[0] if self.sorted_phase_ids else 1
                                        interval = self.phases_config[p_id]["interval"]
                                        
                                        # Initialisiere Watchlist-Eintrag
                                        self.watchlist[mint] = {
                                            "meta": db_streams[mint],
                                            "buffer": self.get_empty_buffer(),
                                            "next_flush": now_ts + interval,
                                            "interval": interval
                                        }
                                        self.subscribed_mints.add(mint)
                                        
                                        # R√úCKWIRKENDE BERECHNUNG: Verarbeite verpasste Trades aus dem Buffer
                                        created_at = db_streams[mint]["created_at"]
                                        started_at = db_streams[mint]["started_at"]
                                        
                                        # Pr√ºfe ob Coin bereits abonniert war (entweder √ºber NewToken-Listener oder hat Trades im Buffer)
                                        # Wenn Coin Trades im Buffer hat, bedeutet das dass er bereits abonniert war
                                        has_buffer = mint in self.trade_buffer
                                        is_early_subscribed = mint in self.early_subscribed_mints
                                        buffer_size = len(self.trade_buffer.get(mint, []))
                                        
                                        # DEBUG: Pr√ºfe ob Coin im trade_buffer ist (auch mit Teilstring-Match)
                                        buffer_keys_match = [k for k in self.trade_buffer.keys() if k[:8] == mint[:8]]
                                        
                                        print(f"üîç {mint[:8]}...: early_subscribed={is_early_subscribed}, has_buffer={has_buffer}, buffer_size={buffer_size}", flush=True)
                                        if buffer_keys_match and not has_buffer:
                                            print(f"‚ö†Ô∏è  {mint[:8]}...: Coin nicht exakt im Buffer, aber √§hnliche Keys gefunden: {[k[:12] + '...' for k in buffer_keys_match[:3]]}", flush=True)
                                        
                                        # Pr√ºfe auch ob ein √§hnlicher Coin im Buffer ist (f√ºr den Fall dass Adressen leicht abweichen)
                                        buffer_match = None
                                        if not has_buffer and buffer_keys_match:
                                            # Versuche den ersten passenden Coin zu verwenden
                                            buffer_match = buffer_keys_match[0]
                                            print(f"üîÑ {mint[:8]}...: Verwende √§hnlichen Coin aus Buffer: {buffer_match[:12]}...", flush=True)
                                            has_buffer = True  # Verwende den √§hnlichen Coin
                                        
                                        if is_early_subscribed or has_buffer:
                                            # Coin wurde bereits abonniert - verarbeite Buffer r√ºckwirkend
                                            # Verwende buffer_match falls vorhanden, sonst mint
                                            buffer_mint = buffer_match if buffer_match else mint
                                            buffer_trades = self.process_trades_from_buffer(buffer_mint, created_at, started_at)
                                            total_buffer_trades += buffer_trades
                                            if buffer_trades > 0:
                                                print(f"‚úÖ {mint[:8]}...: {buffer_trades} Trades aus Buffer verarbeitet", flush=True)
                                            elif has_buffer:
                                                actual_buffer_size = len(self.trade_buffer.get(buffer_mint, []))
                                                print(f"‚ÑπÔ∏è  {mint[:8]}...: Hat {actual_buffer_size} Trades im Buffer, aber keine wurden verarbeitet (Zeitfenster-Problem?)", flush=True)
                                    
                                    if total_buffer_trades > 0:
                                        print(f"üîÑ R√úCKWIRKEND: {total_buffer_trades} verpasste Trades aus {TRADE_BUFFER_SECONDS}s-Buffer ({TRADE_BUFFER_SECONDS//60} Minuten) verarbeitet", flush=True)
                                    
                                    print(f"‚úÖ {len(to_add)} Coins zum Tracking hinzugef√ºgt. Gesamt: {len(self.watchlist)}", flush=True)
                                
                                tracker_status["db_connected"] = True
                                db_connected.set(1)
                                coins_tracked.set(len(self.watchlist))
                                last_refresh = now_ts
                            except Exception as e:
                                print(f"‚ö†Ô∏è DB Sync Error: {e}. Weiter ohne DB-Update...", flush=True)
                                tracker_status["db_connected"] = False
                                db_connected.set(0)
                                last_refresh = now_ts
                        
                        try:
                            msg = await asyncio.wait_for(ws.recv(), timeout=1.0)
                            last_message_time = time.time()
                            tracker_status["last_message_time"] = last_message_time
                            
                            data = json.loads(msg)
                            trades_received.inc()
                            
                            # Alle Trades (buy/sell) zum Buffer hinzuf√ºgen
                            if "txType" in data and data.get("txType") in ["buy", "sell"]:
                                self.add_trade_to_buffer(data)
                                
                                # Wenn Coin bereits in Watchlist: Sofort verarbeiten
                                if data["mint"] in self.watchlist:
                                    self.process_trade(data)
                                    trades_processed.inc()
                                    tracker_status["total_trades"] += 1
                                    last_trade_timestamp.set(time.time())
                                    
                                    # Log alle 100 Trades einen Status
                                    if tracker_status["total_trades"] % 100 == 0:
                                        print(f"üìà {tracker_status['total_trades']} Trades verarbeitet, {len(self.watchlist)} Coins im Tracking", flush=True)
                        
                        except asyncio.TimeoutError:
                            if time.time() - last_message_time > WS_CONNECTION_TIMEOUT:
                                print(f"‚ö†Ô∏è Keine Nachrichten seit {WS_CONNECTION_TIMEOUT}s - Reconnect", flush=True)
                                raise websockets.exceptions.ConnectionClosed(1006, "Timeout")
                        
                        except websockets.exceptions.ConnectionClosed as e:
                            print(f"üîå Trade-WebSocket Verbindung geschlossen: {e}", flush=True)
                            tracker_status["ws_connected"] = False
                            tracker_status["last_error"] = f"ws_closed: {str(e)[:100]}"
                            ws_connected.set(0)
                            # Stoppe NewToken-Listener Task
                            if 'new_token_task' in locals():
                                new_token_task.cancel()
                            break
                        
                        except json.JSONDecodeError as e:
                            print(f"‚ö†Ô∏è JSON Fehler: {e}", flush=True)
                            continue
                        
                        except Exception as e:
                            print(f"‚ö†Ô∏è WS Receive Error: {e}", flush=True)
                            tracker_status["last_error"] = f"ws_error: {str(e)[:100]}"
                            break
                        
                        # Buffer-Cleanup alle 10 Sekunden
                        if now_ts - self.last_buffer_cleanup > 10:
                            removed = self.cleanup_old_trades_from_buffer(now_ts)
                            if removed > 0:
                                print(f"üßπ Buffer-Cleanup: {removed} alte Trades entfernt", flush=True)
                            self.last_buffer_cleanup = now_ts
                        
                        await self.check_lifecycle_and_flush(now_ts)
            
            except websockets.exceptions.WebSocketException as e:
                tracker_status["ws_connected"] = False
                tracker_status["last_error"] = f"ws_exception: {str(e)[:100]}"
                ws_connected.set(0)
                ws_reconnects.inc()
                print(f"‚ùå WebSocket Exception: {e}", flush=True)
                reconnect_count += 1
                tracker_status["reconnect_count"] = reconnect_count
            
            except Exception as e:
                tracker_status["ws_connected"] = False
                tracker_status["last_error"] = f"unexpected: {str(e)[:100]}"
                ws_connected.set(0)
                ws_reconnects.inc()
                print(f"‚ùå Unerwarteter Fehler: {e}", flush=True)
                reconnect_count += 1
                tracker_status["reconnect_count"] = reconnect_count
            
            delay = min(WS_RETRY_DELAY * (1 + reconnect_count * 0.5), WS_MAX_RETRY_DELAY)
            print(f"‚è≥ Reconnect in {delay:.1f}s...", flush=True)
            await asyncio.sleep(delay)
            
            if not tracker_status["db_connected"]:
                print("üîÑ DB auch getrennt, versuche Reconnect...", flush=True)
                await self.init_db_connection()

    def add_trade_to_buffer(self, data):
        f"""F√ºgt einen Trade zum {TRADE_BUFFER_SECONDS}-Sekunden-Buffer hinzu"""
        mint = data.get("mint")
        if not mint:
            return
        
        if mint not in self.trade_buffer:
            self.trade_buffer[mint] = []
        
        trade_entry = (time.time(), data)
        self.trade_buffer[mint].append(trade_entry)
        buffer_trades_total.inc()
        
        # Begrenze Buffer-Gr√∂√üe pro Coin (max 5000 Trades f√ºr 3 Minuten = ~27 Trades/Sekunde)
        if len(self.trade_buffer[mint]) > 5000:
            self.trade_buffer[mint] = self.trade_buffer[mint][-5000:]
    
    def cleanup_old_trades_from_buffer(self, now_ts):
        """Entfernt Trades aus dem Buffer, die √§lter als TRADE_BUFFER_SECONDS sind"""
        cutoff_time = now_ts - TRADE_BUFFER_SECONDS
        total_removed = 0
        
        for mint in list(self.trade_buffer.keys()):
            original_len = len(self.trade_buffer[mint])
            self.trade_buffer[mint] = [
                (ts, data) for ts, data in self.trade_buffer[mint]
                if ts > cutoff_time
            ]
            removed = original_len - len(self.trade_buffer[mint])
            total_removed += removed
            
            # Entferne leere Eintr√§ge
            if not self.trade_buffer[mint]:
                del self.trade_buffer[mint]
        
        # Update Prometheus Metric
        total_buffer_size = sum(len(trades) for trades in self.trade_buffer.values())
        buffer_size.set(total_buffer_size)
        
        return total_removed
    
    def process_trades_from_buffer(self, mint, created_at, started_at):
        """Verarbeitet verpasste Trades aus dem Buffer f√ºr einen neu aktivierten Coin (r√ºckwirkend)"""
        if mint not in self.trade_buffer:
            print(f"‚ÑπÔ∏è  {mint[:8]}...: Keine Trades im Buffer", flush=True)
            return 0
        
        # Konvertiere Timestamps zu Unix-Timestamp
        if created_at.tzinfo is None:
            created_at = created_at.replace(tzinfo=timezone.utc)
        if started_at.tzinfo is None:
            started_at = started_at.replace(tzinfo=timezone.utc)
        
        created_ts = created_at.timestamp()
        started_ts = started_at.timestamp()
        now_ts = time.time()
        
        # Finde alle Trades im relevanten Zeitraum
        # Zeitraum: created_at bis jetzt (alle Trades die zwischen Coin-Erstellung und Aktivierung passiert sind)
        # Aber maximal TRADE_BUFFER_SECONDS (180 Sekunden = 3 Minuten) zur√ºck
        # WICHTIG: Wenn started_at gerade gesetzt wurde (NOW()), dann sollten ALLE Trades im Buffer verarbeitet werden
        # die zwischen created_at und jetzt passiert sind
        cutoff_ts = max(created_ts, now_ts - TRADE_BUFFER_SECONDS)
        # end_ts sollte jetzt sein, damit alle Trades bis zur Aktivierung verarbeitet werden
        end_ts = now_ts
        
        print(f"üîç {mint[:8]}...: Pr√ºfe Buffer - created_ts={created_ts:.1f}, started_ts={started_ts:.1f}, now_ts={now_ts:.1f}, cutoff_ts={cutoff_ts:.1f}, end_ts={end_ts:.1f}", flush=True)
        print(f"üîç {mint[:8]}...: Buffer hat {len(self.trade_buffer[mint])} Trades", flush=True)
        
        relevant_trades = []
        for trade_ts, trade_data in self.trade_buffer[mint]:
            # Trade muss im relevanten Zeitraum liegen
            if cutoff_ts <= trade_ts <= end_ts:
                relevant_trades.append((trade_ts, trade_data))
        
        print(f"üîç {mint[:8]}...: {len(relevant_trades)} relevante Trades gefunden", flush=True)
        
        # Sortiere nach Timestamp (√§lteste zuerst) f√ºr chronologische Verarbeitung
        relevant_trades.sort(key=lambda x: x[0])
        
        # Verarbeite alle relevanten Trades chronologisch
        processed_count = 0
        for trade_ts, trade_data in relevant_trades:
            if mint in self.watchlist:
                self.process_trade(trade_data)
                processed_count += 1
                trades_from_buffer.inc()
            else:
                print(f"‚ö†Ô∏è  {mint[:8]}...: Trade kann nicht verarbeitet werden - Coin nicht in Watchlist", flush=True)
        
        if processed_count > 0:
            mint_short = mint[:8] + "..." if len(mint) > 8 else mint
            time_range = f"{int(end_ts - cutoff_ts)}s"
            print(f"üîÑ Buffer: {processed_count} r√ºckwirkende Trades f√ºr {mint_short} verarbeitet (Zeitraum: {time_range})", flush=True)
        
        return processed_count
    
    def process_trade(self, data):
        """Verarbeitet einen einzelnen Trade (direkt oder aus Buffer)"""
        mint = data["mint"]
        if mint not in self.watchlist: return
        entry = self.watchlist[mint]
        buf = entry["buffer"]
        try:
            sol = float(data["solAmount"])
            price = float(data["vSolInBondingCurve"]) / float(data["vTokensInBondingCurve"])
            is_buy = data["txType"] == "buy"
        except: return
        if buf["open"] is None: buf["open"] = price
        buf["close"] = price
        buf["high"] = max(buf["high"], price)
        buf["low"] = min(buf["low"], price)
        buf["vol"] += sol
        if is_buy:
            buf["buys"] += 1
            buf["vol_buy"] += sol
            buf["max_buy"] = max(buf["max_buy"], sol)
        else:
            buf["sells"] += 1
            buf["vol_sell"] += sol
            buf["max_sell"] = max(buf["max_sell"], sol)
        if sol < 0.01: buf["micro_trades"] += 1
        buf["wallets"].add(data["traderPublicKey"])
        buf["v_sol"] = float(data["vSolInBondingCurve"])
        buf["mcap"] = price * 1_000_000_000

    async def check_lifecycle_and_flush(self, now_ts):
        batch_data = []
        phases_in_batch = []
        now_utc = datetime.now(timezone.utc)
        now_berlin = datetime.now(GERMAN_TZ)
        
        for mint, entry in list(self.watchlist.items()):
            buf = entry["buffer"]
            current_bonding_pct = (buf["v_sol"] / SOL_RESERVES_FULL) * 100
            if current_bonding_pct >= 99.5:
                await self.stop_tracking(mint, is_graduation=True)
                continue
            created_at = entry["meta"]["created_at"]
            current_pid = entry["meta"]["phase_id"]
            diff = now_utc - created_at
            age_minutes = (diff.total_seconds() / 60) - AGE_CALCULATION_OFFSET_MIN
            if age_minutes < 0: age_minutes = 0
            phase_cfg = self.phases_config.get(current_pid)
            if phase_cfg and age_minutes > phase_cfg["max_age"]:
                next_pid = None
                for pid in self.sorted_phase_ids:
                    if pid > current_pid:
                        next_pid = pid
                        break
                if next_pid is None or next_pid >= 99:
                    await self.stop_tracking(mint, is_graduation=False)
                    continue
                else:
                    await self.switch_phase(mint, current_pid, next_pid)
                    entry["meta"]["phase_id"] = next_pid
                    new_interval = self.phases_config[next_pid]["interval"]
                    entry["interval"] = new_interval
                    entry["next_flush"] = now_ts + new_interval
            if now_ts >= entry["next_flush"]:
                if buf["vol"] > 0:
                    is_koth = buf["mcap"] > 30000
                    batch_data.append((
                        mint, now_berlin, entry["meta"]["phase_id"],
                        buf["open"], buf["high"], buf["low"], buf["close"], buf["mcap"],
                        current_bonding_pct, buf["v_sol"], is_koth,
                        buf["vol"], buf["vol_buy"], buf["vol_sell"],
                        buf["buys"], buf["sells"], len(buf["wallets"]), buf["micro_trades"],
                        0, buf["max_buy"], buf["max_sell"]
                    ))
                    phases_in_batch.append(entry["meta"]["phase_id"])
                entry["buffer"] = self.get_empty_buffer()
                entry["next_flush"] = now_ts + entry["interval"]
        
        if batch_data and tracker_status["db_connected"]:
            sql = """
                INSERT INTO coin_metrics (
                    mint, timestamp, phase_id_at_time,
                    price_open, price_high, price_low, price_close, market_cap_close,
                    bonding_curve_pct, virtual_sol_reserves, is_koth,
                    volume_sol, buy_volume_sol, sell_volume_sol,
                    num_buys, num_sells, unique_wallets, num_micro_trades,
                    dev_sold_amount, max_single_buy_sol, max_single_sell_sol
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14, $15, $16, $17, $18, $19, $20, $21)
            """
            try:
                with flush_duration.time():
                    async with self.pool.acquire() as conn:
                        await conn.executemany(sql, batch_data)
                counts = Counter(phases_in_batch)
                details = ", ".join([f"Phase {k}: {v}" for k,v in sorted(counts.items())])
                
                # Detailliertes Logging
                print(f"üíæ Saved metrics for {len(batch_data)} coins ({details})", flush=True)
                
                # Zeige Details f√ºr die ersten 3 Coins als Beispiel
                for i, (mint, timestamp, phase_id, *rest) in enumerate(batch_data[:3]):
                    mint_short = mint[:8] + "..." if len(mint) > 8 else mint
                    print(f"   ‚úì {mint_short} - Phase {phase_id} - {timestamp.strftime('%H:%M:%S')}", flush=True)
                
                if len(batch_data) > 3:
                    print(f"   ... und {len(batch_data) - 3} weitere Coins", flush=True)
                
                metrics_saved.inc(len(batch_data))
                tracker_status["total_metrics_saved"] += len(batch_data)
                print(f"üìä Gesamt gespeichert: {tracker_status['total_metrics_saved']} Metriken", flush=True)
            except Exception as e:
                print(f"‚ö†Ô∏è SQL Error: {e}. Daten gehen verloren!", flush=True)
                tracker_status["db_connected"] = False
                db_connected.set(0)
                db_errors.labels(type="insert").inc()
        elif batch_data and not tracker_status["db_connected"]:
            print(f"‚ö†Ô∏è {len(batch_data)} Datenpunkte verloren (DB nicht verbunden)", flush=True)
            print(f"   Betroffene Coins: {[mint[:8] + '...' if len(mint) > 8 else mint for mint, *_ in batch_data[:5]]}", flush=True)

async def start_tracker():
    global _tracker_instance
    tracker = Tracker()
    # Speichere Tracker-Instanz f√ºr Health-Check
    _tracker_instance = tracker
    await tracker.run()

async def main():
    # Starte Health-Server ZUERST, damit er sofort verf√ºgbar ist
    health_task = asyncio.create_task(start_health_server())
    # Warte kurz, damit Health-Server startet
    await asyncio.sleep(1)
    
    print(f"üîß Konfiguration:", flush=True)
    print(f"  - DB_REFRESH_INTERVAL: {DB_REFRESH_INTERVAL}s", flush=True)
    print(f"  - WS_PING_INTERVAL: {WS_PING_INTERVAL}s", flush=True)
    print(f"  - WS_CONNECTION_TIMEOUT: {WS_CONNECTION_TIMEOUT}s", flush=True)
    print(f"  - WS_URI: {WS_URI}", flush=True)
    print(f"  - TRADE_BUFFER_SECONDS: {TRADE_BUFFER_SECONDS}s ({TRADE_BUFFER_SECONDS//60} Minuten) (Pre-Subscription + Buffer)", flush=True)
    # Health-Server l√§uft bereits (wurde oben gestartet)
    # Starte nur noch den Tracker
    await start_tracker()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nüëã Shutdown...", flush=True)

